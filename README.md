# LLMBench â€“ Benchmarker de modÃ¨les LLM via API OpenAI-compatible

Ce script Python permet de benchmarker des modÃ¨les LLM compatibles avec l'API OpenAI (v1/chat/completions), en mesurant :
- le taux de rÃ©ussite,
- la latence moyenne,
- le dÃ©bit en tokens/seconde.

Il utilise des prompts de qualitÃ© extraits de [Awesome ChatGPT Prompts](https://huggingface.co/datasets/fka/awesome-chatgpt-prompts).

## ğŸš€ PrÃ©requis

- Python 3.9+
- AccÃ¨s Ã  une API OpenAI-compatible (e.g. vLLM, LiteLLM, Mistral, etc.)

## ğŸ§ª Installation

```bash
git clone https://github.com/<ton-utilisateur>/llmbench.git
cd llmbench
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
````

## âš™ï¸ Configuration

Ã‰dite les variables `API_URL`, `API_KEY`, et `MODEL` dans `app.py` pour tester un modÃ¨le spÃ©cifique.

## â–¶ï¸ Utilisation

```bash
python app.py
```

## ğŸ“¦ Dataset utilisÃ©

[Awesome ChatGPT Prompts](https://huggingface.co/datasets/fka/awesome-chatgpt-prompts)

## ğŸ“„ Licence

MIT

````

---

### ğŸ“„ **2. `requirements.txt`**

```txt
aiohttp
datasets
tqdm
tiktoken
````

---

### ğŸ“„ **3. `LICENSE`** (MIT, option par dÃ©faut)

```txt
MIT License

Copyright (c) 2025 Antonio

Permission is hereby granted, free of charge, to any person obtaining a copy...
```

